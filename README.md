# Instructions for setting up the data and environment

## Unzip the files in the Terminal
1. Open the terminal by clicking on the tab "Terminal" in IDE  
2. Dataset provided is already in your Folder and is saved as a "zip" file  
3. Unzip the file  

## Running Code on pySpark  
Install pySpark  -> source scala-spark.sh  
Submit pySpark code -> spark-submit yourcode.py  
  
## Running Code on Scala Spark
Install Scala Spark -> source scala-spark.sh  
Run Scala Spark Code -> spark-shell -i yourcode.scala  

# Test Instructions
1. Make sure you complete the code for each of the questions. 
2. Please save your code in answers.py for pySpark and answers.scala for Scala-Spark (Please create file in the IDE)
3. Although the User Interface shows 1 question but the initial text has all the 6 questions that needs to be answered. 
4. The scoring script doesnt work, so dont rely on it. 
5. We are looking for quality, efficiency and logic of your code and not the correct answer. Obviously, we would look for if your code actually works
6. Also, you are expected to solve the case study using DataFrames and RDDs. Code written with SparkSQL will not be considered. 


# Best of Luck!!!!
