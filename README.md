# Instructions for setting up the data and environment

## Unzip the files in the Terminal
1. Open the terminal by clicking on the tab "Terminal" in IDE  
2. Dataset provided is already in your Folder and is saved as a "zip" file  
3. Unzip the file  

## Running Code on pySpark 
Install pySpark  -> pip install -r requirements.txt --user  
Submit pySpark code -> spark-submit yourcode.py  
  
## Running Code on Scala Spark
Install Scala Spark -> source scala-spark.sh  
Run Scala Spark Code -> spark-shell -i yourcode.scala  

# Test Instructions
1. Make sure you complete the code for each of the questions. 
2. Although the User Interface shows 1 question but the initial text has all the 6 questions that needs to be answered. 
3. The scoring script doesnt work, so dont rely on it. 
4. We are looking for quality, efficiency and logic of your code and not the correct answer. Obviously, we would look for if your code actually works
5. Also, you are expected to solve the case study using DataFrames and RDDs. Code written with SparkSQL will not be considered. 


# Best of Luck!!!!
